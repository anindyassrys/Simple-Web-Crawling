{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import library"
      ],
      "metadata": {
        "id": "HaY6hmU-OBF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "4zDq4eX_MCpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCOND2DgKFfp",
        "outputId": "d880e449-ddb3-4db4-98d2-62263b683f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Web crawler - Wikipedia\n",
            "Number of links: 712\n",
            "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
            "https://af.wikipedia.org/wiki/Webkruiper\n",
            "https://ar.wikipedia.org/wiki/%D8%B2%D8%A7%D8%AD%D9%81_%D8%A7%D9%84%D8%B4%D8%A8%D9%83%D8%A9\n",
            "https://bar.wikipedia.org/wiki/Webcrawler\n",
            "https://ca.wikipedia.org/wiki/Aranya_web\n",
            "https://cs.wikipedia.org/wiki/Web_crawler\n",
            "https://cy.wikipedia.org/wiki/Ymgripiwr_gwe\n",
            "https://ary.wikipedia.org/wiki/%D8%B1%D8%AA%D9%8A%D9%84%D8%A9_(%D8%A8%D9%88%D8%AA)\n",
            "https://de.wikipedia.org/wiki/Webcrawler\n",
            "https://el.wikipedia.org/wiki/%CE%91%CE%BD%CE%B9%CF%87%CE%BD%CE%B5%CF%85%CF%84%CE%AE%CF%82_%CE%B9%CF%83%CF%84%CE%BF%CF%8D\n",
            "https://es.wikipedia.org/wiki/Ara%C3%B1a_web\n",
            "https://eu.wikipedia.org/wiki/Web_crawler\n",
            "https://fa.wikipedia.org/wiki/%D8%AE%D8%B2%D9%86%D8%AF%D9%87_%D9%88%D8%A8\n",
            "https://fr.wikipedia.org/wiki/Robot_d%27indexation\n",
            "https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC\n",
            "https://hy.wikipedia.org/wiki/%D5%88%D6%80%D5%B8%D5%B6%D5%B8%D5%B2%D5%A1%D5%AF%D5%A1%D5%B6_%D5%BC%D5%B8%D5%A2%D5%B8%D5%BF\n",
            "https://hr.wikipedia.org/wiki/Web_pauk\n",
            "https://id.wikipedia.org/wiki/Perayap_web\n",
            "https://ia.wikipedia.org/wiki/Rastreator_de_rete\n",
            "https://it.wikipedia.org/wiki/Crawler\n",
            "https://he.wikipedia.org/wiki/%D7%96%D7%97%D7%9C%D7%9F_%D7%A8%D7%A9%D7%AA\n",
            "https://lt.wikipedia.org/wiki/Interneto_robotas\n",
            "https://hu.wikipedia.org/wiki/Keres%C5%91robot\n",
            "https://ms.wikipedia.org/wiki/Perangkak_web\n",
            "https://nl.wikipedia.org/wiki/Spider\n",
            "https://nds-nl.wikipedia.org/wiki/Webkroeper\n",
            "https://ja.wikipedia.org/wiki/%E3%82%AF%E3%83%AD%E3%83%BC%E3%83%A9\n",
            "https://no.wikipedia.org/wiki/S%C3%B8kerobot\n",
            "https://nn.wikipedia.org/wiki/S%C3%B8kerobot\n",
            "https://mhr.wikipedia.org/wiki/%D0%9A%D1%8B%D1%87%D0%B0%D0%BB%D1%88%D0%B5_%D1%80%D0%BE%D0%B1%D0%BE%D1%82\n",
            "https://pl.wikipedia.org/wiki/Robot_internetowy\n",
            "https://pt.wikipedia.org/wiki/Rastreador_web\n",
            "https://ro.wikipedia.org/wiki/Robot_de_c%C4%83utare\n",
            "https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D0%B8%D1%81%D0%BA%D0%BE%D0%B2%D1%8B%D0%B9_%D1%80%D0%BE%D0%B1%D0%BE%D1%82\n",
            "https://simple.wikipedia.org/wiki/Web_crawler\n",
            "https://sr.wikipedia.org/wiki/Veb-popisiva%C4%8D\n",
            "https://fi.wikipedia.org/wiki/Hakurobotti\n",
            "https://sv.wikipedia.org/wiki/Spindel_(internet)\n",
            "https://ta.wikipedia.org/wiki/%E0%AE%B5%E0%AE%B2%E0%AF%88_%E0%AE%8A%E0%AE%B0%E0%AF%8D%E0%AE%A4%E0%AE%BF\n",
            "https://th.wikipedia.org/wiki/%E0%B9%80%E0%B8%A7%E0%B9%87%E0%B8%9A%E0%B8%84%E0%B8%A3%E0%B8%AD%E0%B8%A7%E0%B9%8C%E0%B9%80%E0%B8%A5%E0%B8%AD%E0%B8%A3%E0%B9%8C\n",
            "https://tr.wikipedia.org/wiki/Arama_robotu\n",
            "https://uk.wikipedia.org/wiki/%D0%9F%D0%BE%D1%88%D1%83%D0%BA%D0%BE%D0%B2%D0%B8%D0%B9_%D1%80%D0%BE%D0%B1%D0%BE%D1%82\n",
            "https://zh-classical.wikipedia.org/wiki/%E7%88%AC%E7%B6%B2%E8%9F%B2%E6%A2%B0\n",
            "https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2\n",
            "https://www.wikidata.org/wiki/Special:EntityPage/Q45842#sitelinks-wikipedia\n",
            "https://www.wikidata.org/wiki/Special:EntityPage/Q45842\n",
            "https://web.archive.org/web/20211206205907/https://webbrowsersintroduction.com/\n",
            "https://webbrowsersintroduction.com/\n",
            "https://web.archive.org/web/20040903174942/http://archive.ncsa.uiuc.edu/SDG/IT94/Proceedings/Agents/spetka/spetka.html\n",
            "http://archive.ncsa.uiuc.edu/SDG/IT94/Proceedings/Agents/spetka/spetka.html\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.126.6094\n",
            "https://doi.org/10.1145%2F358923.358934\n",
            "https://api.semanticscholar.org/CorpusID:3710903\n",
            "http://wiki.foaf-project.org/w/Scutter\n",
            "https://web.archive.org/web/20091213213920/http://wiki.foaf-project.org/w/Scutter\n",
            "https://www.springer.com/gp/book/9783540233381\n",
            "http://www10.org/cdrom/papers/210/index.html\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1018.1506\n",
            "https://doi.org/10.1145%2F371920.371960\n",
            "https://api.semanticscholar.org/CorpusID:10316730\n",
            "http://chato.cl/research/crawling_thesis\n",
            "https://doi.org/10.1145%2F1062745.1062789\n",
            "https://doi.org/10.1038%2F21987\n",
            "https://ui.adsabs.harvard.edu/abs/1999Natur.400..107L\n",
            "https://doi.org/10.1038%2F21987\n",
            "https://pubmed.ncbi.nlm.nih.gov/10428673\n",
            "https://api.semanticscholar.org/CorpusID:4347646\n",
            "http://ilpubs.stanford.edu:8090/347/\n",
            "https://doi.org/10.1142%2F3725\n",
            "http://oak.cs.ucla.edu/~cho/papers/cho-thesis.pdf\n",
            "http://www10.org/cdrom/papers/pdf/p208.pdf\n",
            "http://www2003.org/cdrom/papers/refereed/p007/p7-abiteboul.html\n",
            "https://doi.org/10.1145%2F775152.775192\n",
            "https://web.archive.org/web/20090320030833/http://vigna.dsi.unimi.it/ftp/papers/UbiCrawler.pdf\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.2.5538\n",
            "https://doi.org/10.1002%2Fspe.587\n",
            "https://api.semanticscholar.org/CorpusID:325714\n",
            "http://vigna.dsi.unimi.it/ftp/papers/UbiCrawler.pdf\n",
            "http://vigna.dsi.unimi.it/ftp/papers/ParadoxicalPageRank.pdf\n",
            "https://doi.org/10.1007%2F978-3-540-30216-2_14\n",
            "http://chato.cl/papers/baeza05_crawling_country_better_breadth_first_web_page_ordering.pdf\n",
            "https://www.researchgate.net/publication/220724572_A_Fast_Community_Based_Algorithm_for_Generating_Web_Crawler_Seeds_Set\n",
            "https://web.archive.org/web/20090320030832/http://dollar.biz.uiowa.edu/~pant/Papers/crawling.pdf\n",
            "http://dollar.biz.uiowa.edu/~pant/Papers/crawling.pdf\n",
            "http://www.scit.wlv.ac.uk/~in7803/publications/cothey_2004.pdf\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.117.185\n",
            "https://doi.org/10.1002%2Fasi.20078\n",
            "http://informatics.indiana.edu/fil/Papers/ICML.ps\n",
            "https://web.archive.org/web/20121221113620/http://informatics.indiana.edu/fil/Papers/ICML.ps\n",
            "http://informatics.indiana.edu/fil/Papers/AA98.ps\n",
            "https://web.archive.org/web/20121221113630/http://informatics.indiana.edu/fil/Papers/AA98.ps\n",
            "https://web.archive.org/web/20040317210216/http://www.fxpal.com/people/vdberg/pubs/www8/www1999f.pdf\n",
            "https://doi.org/10.1016%2Fs1389-1286%2899%2900052-3\n",
            "http://www.fxpal.com/people/vdberg/pubs/www8/www1999f.pdf\n",
            "https://web.archive.org/web/20010904075500/http://archive.ncsa.uiuc.edu/SDG/IT94/Proceedings/Searching/pinkerton/WebCrawler.html\n",
            "http://clgiles.ist.psu.edu/papers/VLDB-2000-focused-crawling.pdf\n",
            "https://doi.org/10.1145%2F2389936.2389949\n",
            "https://api.semanticscholar.org/CorpusID:18513666\n",
            "https://doi.org/10.1145%2F2380718.2380762\n",
            "https://api.semanticscholar.org/CorpusID:16718130\n",
            "https://www.researchgate.net/publication/44241179\n",
            "https://doi.org/10.1007%2F978-3-642-02457-3_74\n",
            "https://hdl.handle.net/20.500.11937%2F48288\n",
            "https://www.researchgate.net/publication/264620349\n",
            "https://doi.org/10.1002%2Fcpe.2980\n",
            "https://api.semanticscholar.org/CorpusID:205690364\n",
            "http://www.cs.brown.edu/courses/cs227/2002/cache/Cho.pdf\n",
            "https://doi.org/10.1145%2F342009.335391\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.6087\n",
            "https://doi.org/10.1002%2F%28SICI%291099-1425%28199806%291%3A1%3C15%3A%3AAID-JOS3%3E3.0.CO%3B2-K\n",
            "https://doi.org/10.1145%2F958942.958945\n",
            "https://api.semanticscholar.org/CorpusID:147958\n",
            "https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.59.5877\n",
            "https://doi.org/10.1145%2F857166.857170\n",
            "https://api.semanticscholar.org/CorpusID:9362566\n",
            "http://pages.stern.nyu.edu/~panos/publications/icde2005.pdf\n",
            "http://www.robotstxt.org/wc/exclusion.html\n",
            "https://web.archive.org/web/20071107021800/http://www.robotstxt.org/wc/exclusion.html\n",
            "http://www.robotstxt.org/wc/guidelines.html\n",
            "https://web.archive.org/web/20050422045839/http://www.robotstxt.org/wc/guidelines.html\n",
            "http://www.chato.cl/papers/baeza02balancing.pdf\n",
            "https://web.archive.org/web/20060219085958/http://www.cindoc.csic.es/cybermetrics/pdf/68.pdf\n",
            "http://www.cindoc.csic.es/cybermetrics/pdf/68.pdf\n",
            "http://www.mccurley.org/papers/fractal.pdf\n",
            "https://doi.org/10.1145%2F572326.572328\n",
            "https://api.semanticscholar.org/CorpusID:6416041\n",
            "http://www.scit.wlv.ac.uk/%7Ecm1993/papers/Web_Crawling_Ethics_preprint.doc\n",
            "https://doi.org/10.1002%2Fasi.20388\n",
            "http://infolab.stanford.edu/~backrub/google.html\n",
            "https://doi.org/10.1016%2Fs0169-7552%2898%2900110-x\n",
            "http://cis.poly.edu/tr/tr-cis-2001-03.pdf\n",
            "https://oa.doria.fi/handle/10024/38506\n",
            "https://web.archive.org/web/20140706120641/https://oa.doria.fi/handle/10024/38506\n",
            "https://arxiv.org/abs/cs/0503069\n",
            "https://ui.adsabs.harvard.edu/abs/2005cs........3069N\n",
            "http://www.mendeley.com/download/public/1423991/3893295922/dc0f7d824fd2a8fbbc84f6fdf9e4f337d343987d/dl.pdf\n",
            "https://doi.org/10.1016%2Fs0169-023x%2804%2900107-7\n",
            "https://support.google.com/webmasters/bin/answer.py?hl=en&answer=174992\n",
            "http://semanticweb.com/more-semantics-for-google-ita-software-acquisition-comes-with-needlebase-too_b19329\n",
            "https://support.apple.com/en-us/HT204683\n",
            "https://www.wired.com/2007/01/tax-takers-send-in-the-spiders/\n",
            "https://web.archive.org/web/20161222185208/https://www.wired.com/2007/01/tax-takers-send-in-the-spiders/\n",
            "https://www.canada.ca/en/revenue-agency/services/about-canada-revenue-agency-cra/protecting-your-privacy/privacy-impact-assessment/xenon-web-crawling-initiative-privacy-impact-assessment-summary.html\n",
            "https://web.archive.org/web/20170925203155/https://www.canada.ca/en/revenue-agency/services/about-canada-revenue-agency-cra/protecting-your-privacy/privacy-impact-assessment/xenon-web-crawling-initiative-privacy-impact-assessment-summary.html\n",
            "http://oak.cs.ucla.edu/~cho/research/crawl.html\n",
            "http://www.wiley.com/legacy/compbooks/sonnenreich/history.html\n",
            "https://github.com/bedirhan/wivet\n",
            "https://www.slideshare.net/denshe/icwe13-tutorial-webcrawling\n",
            "https://www.slideshare.net/denshe/intelligent-crawling-shestakovwiiat13\n",
            "https://en.wikipedia.org/w/index.php?title=Template:Internet_search&action=edit\n",
            "https://en.wikipedia.org/w/index.php?title=Template:Web_crawlers&action=edit\n",
            "https://www.wikidata.org/wiki/Q45842#identifiers\n",
            "https://d-nb.info/gnd/4796298-7\n",
            "https://en.wikipedia.org/w/index.php?title=Web_crawler&oldid=1148994360\n",
            "https://foundation.wikimedia.org/wiki/Privacy_policy\n",
            "https://developer.wikimedia.org\n",
            "https://stats.wikimedia.org/#/en.wikipedia.org\n",
            "https://foundation.wikimedia.org/wiki/Cookie_statement\n",
            "https://wikimediafoundation.org/\n",
            "https://www.mediawiki.org/\n"
          ]
        }
      ],
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Web_crawler\"\n",
        "\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    html = response.content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    title = soup.title.text.strip()\n",
        "    print(f\"Title: {title}\")\n",
        "    links = soup.find_all(\"a\")\n",
        "    print(f\"Number of links: {len(links)}\")\n",
        "    for link in links:\n",
        "        href = link.get(\"href\")\n",
        "        if href and \"http\" in href:\n",
        "            print(href)\n",
        "else:\n",
        "    print(f\"Request failed with status code {response.status_code}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is a simple web scraper that fetches the contents of a Wikipedia page on web crawlers and prints the page's title, the number of links on the page, and all external links found on the page.\n",
        "\n",
        "The code first sends a GET request to the specified URL using the requests library and checks if the response code is 200, which indicates that the request was successful. If the request was successful, the code uses the BeautifulSoup library to parse the HTML content of the page and extract the page's title.\n",
        "\n",
        "Next, the code uses find_all() method to find all the a tags on the page which represent links. It then prints the total number of links found on the page. The code then loops through all the links and checks if each link has an href attribute and if it is an external link. If both conditions are met, the link is printed.\n",
        "\n",
        "If the request was not successful, the code prints an error message indicating the status code returned by the server."
      ],
      "metadata": {
        "id": "Y3jrwiMGOhw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's store it into csv files\n"
      ],
      "metadata": {
        "id": "Pb8sjGKxNGWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "if response.status_code == 200:\n",
        "    html = response.content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    title = soup.title.text.strip()\n",
        "    links = soup.find_all(\"a\")\n",
        "    \n",
        "    with open('output.csv', mode='w', encoding='utf-8', newline='') as csv_file:\n",
        "        fieldnames = ['link']\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        \n",
        "        for link in links:\n",
        "            href = link.get(\"href\")\n",
        "            if href and \"http\" in href:\n",
        "                writer.writerow({'link': href})\n",
        "else:\n",
        "    print(f\"Request failed with status code {response.status_code}\")"
      ],
      "metadata": {
        "id": "6PyFhRv_NMmq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will create a new CSV file named \"output.csv\" in the same directory as the Python script, and it will write all the links found on the web page to the CSV file."
      ],
      "metadata": {
        "id": "BSP_gZlcOmQl"
      }
    }
  ]
}